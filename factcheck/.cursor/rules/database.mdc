---
description: Database for our project
globs:
alwaysApply: true
---

Always use Context7.

# Overview
This project makes heavy use of code generation tools, e.g. wire and sqlc.
The project is expected to be hosted with PostgreSQL 16, but code is written cleanly
in order to decouple our it from underlying database.

To decouple data from storage, we define data types twice:
1. Database-coupled types
    These types are generated by sqlc under /data
    and is meant to represent the underlying database types.

2. "Domain" types
    These types are defined at root (Go package factcheck itself).
    They are easy to work with compared to the database-coupled variant,
    have normal Go types, and so on. Our code will mostly work with these types.

Adapters to convert between the two are provided in /data/postgres/adapters.go.

To abstract over database interactions, we divide the database access code into 3 layers,
lowest first:

- Data connector layer in /data
    Code in this layer is generated by sqlc. For example, our generated code for PostgreSQL
    lives inside /data/postgres. This layer of database interaction directly uses database-coupled
    types generated by sqlc.

    Note: We might need to add our own initialization/cleanup code in this package to implement
    graceful shutdown with Wire's cleanup function feature, like in postgres.go

- Repository layer in /repo
    Code in this layer is how the rest of our application sees our database interactions.
    These "repositories" use "domain" types, and simplify extra handling that comes with
    type-safe sqlc generated code.

# Integration tests [local]
Despite having Nix flake outputs for integration test components,
I myself do not have Nix on my local machine and rely on running PostgreSQL Docker instance
for integration testing. If you did notice that the database is not up and running,
DO NOT start any services, containers, and processes on your own. Alert me.

# Integration tests [CI]
This project uses [GitHub Actions workflow](/.github/workflows/go-test.yaml)
for automated integration tests. The GitHub Actions workflow makes heavy use of Nix flake,
to pin everything and bring up database container.

# Schema evolution and code change steps
We fully embrace sqlc for our database access. This does mean that if we want
to change anything about database interaction, we'll first have to go and change
sqlc definitions under (data conntector directory)[/factcheck/data].

Due to our heavy use of code generation and rigorous testing, we need to have a
simplified way of addressing changes regarding database interactions, so we divided
our changes into following high-level types

## New queries required
If we need new queries but not new schema for PostgreSQL, then we can just add that
new SQL query to our sqlc definitions inside /data/postgres/query.sql.

We can then run the following command to generate new Go queries:

```shell
sqlc generate
```

## Updating queries
If our existing queries really do need to evolve, then we'll have to:

1. Update SQL queries in /data/postgres/query.sql
2. Generate new data connector code with sqlc
3. Update repository code to support the new SQL queries, if need be

### Schema changes and migrations
When schema changes occur, we'll probably need to do a lot, but probably in this order:

1. Update SQL schema in /data/postgres/query.sql like here https://docs.sqlc.dev/en/latest/howto/ddl.html
2. Generate new data connector code with sqlc to check that our queries are not broken
3. If queries were broken, fix the queries and regenerate
4. Update domain types to match new schema
5. Update repositories to match new domain types
7. Update adapters to address the changes
8. Leave the rest to me

## Go database repository
Most repository methods will just mirror the raw SQL queries, with some addition of option (type Options).

### Go database repository: complex methods
Some repository methods, e.g. `Topics.ListAllTopics`, are simple wrappers over other repository methods.
Some repository methods, e.g. `Topics.ListHome` and `Topics.CountHome`, are "complex wrappers" over other methods queries. These wrappers are for complex business logic use case, where there're many ways to execute a query.

For example, `ListHome` accept 3 query arguments: `like_id`, `like_message_text`, and `status`. Now, we can write 1 SQL query to rule them all, but that would be slow and make the queries complex to understand.

We mitigate this by using sqlc to define multiple queries:

- We first create 3 basic queries for each of the arguments: `ListTopicsLikeID`, `ListTopicsLikeMessageText`, and `ListTopicsByStatus`.
- We then create 3 other queries for 2-combination: `ListTopicsByStatusLikeID`, `ListTopicsByStatusLikeMessageText`, `ListTopicsLikeIDLikeMessageText`
- We lastly create the query for all 3-combination: `ListTopicsByStatusLikeIDLikeMessageText`

These complex wrappers generally have their own option types for defining their parameters.

### Go database repository options
Using options allow us to functionally define some parameters from outside of the repository.
The repository package provides 1 base option type called `Options`, which, as of now, only does database transactions.

Repository methods can "opt-in" to accept this option in the form of functional options `Option`, or they can define their own option types and embedding our base `Options` into it like with `OptionsTopics`.

Common use cases include:

- Setting parameter combo for each method call (as in complex wrappers like `Topics.ListHome`)
- Doing database transactions

### Go database repository transactions
Code generated by sqlc is called "queries", and is represented by an type `*postgres.Queries`.
Now, `postgres.Queries` internally has an executor inside, which could be transactional or non-transactional.

By default, the repository uses non-transactional queries provided by DI.

If however, we determine that a query must be done with transaction, then we can "begin" the transaction object and then send that object to repository methods via `Option`/`Options`. When this happens, all our repository has to do is to get a new `*postgres.Queries` that some how has our transaction object as executor (`*postgres.Queries.WithTX` does that, or we can even call `postgres.New(txObject)` to get it).